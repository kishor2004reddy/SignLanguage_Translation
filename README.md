# ğŸ¤Ÿ Sign Language Translation System (ASL)

A real-time **Sign Language Translation** system that recognizes **American Sign Language (ASL) hand gestures** using a webcam and converts them into readable text. The project leverages **Computer Vision, MediaPipe, and Deep Learning (MobileNetV2)** for accurate and smooth real-time predictions.

---

## ğŸ“Œ Project Overview

This project captures live video from a webcam, detects hands using **MediaPipe Hands**, and classifies ASL gestures using a **MobileNetV2-based CNN model** trained on the ASL Alphabet dataset. Predictions are stabilized using a rolling buffer and displayed as a sentence in real time.

---

## âœ¨ Features

- ğŸ¥ Real-time webcam-based ASL recognition  
- âœ‹ Hand detection using MediaPipe  
- ğŸ§  Deep learning with MobileNetV2  
- ğŸ”„ Prediction smoothing with deque buffer  
- ğŸ“ Live sentence formation  
- âš¡ Efficient and lightweight for real-time use  

---

## ğŸ§  Model Details

- Backbone: MobileNetV2 (ImageNet pretrained)  
- Input Size: 224 Ã— 224 Ã— 3  
- Layers:
  - Data Augmentation
  - Global Average Pooling
  - Dropout (0.3)
  - Dense Softmax Output  
- Training:
  - Transfer Learning
  - Fine-tuning last 30 layers  
- Number of Classes: 29 (ASL signs)

---

## ğŸ—‚ï¸ Project Structure

SignLanguage_Translation/
â”‚
â”œâ”€â”€ app.py                # Real-time ASL translation script  
â”œâ”€â”€ asl_translation.ipynb # Model training notebook  
â”œâ”€â”€ model.h5              # Trained model weights  
â”œâ”€â”€ asl_labels.json       # Label mappings  
â”œâ”€â”€ requirements.txt      # Dependencies  
â””â”€â”€ README.md             # Documentation  

---

## ğŸš€ How It Works

1. Captures live video from webcam  
2. Detects hand landmarks using MediaPipe  
3. Crops and preprocesses hand region  
4. Passes image to trained CNN model  
5. Smooths predictions using buffer  
6. Forms sentence from detected signs  
7. Displays translated text in real time  

---

## ğŸ› ï¸ Installation

### Clone Repository
```bash
git clone https://github.com/kishor2004reddy/SignLanguage_Translation.git  
cd SignLanguage_Translation
```

### Install Dependencies
```bash
pip install -r requirements.txt  
```

Required:
- Python 3.8+
- OpenCV
- MediaPipe
- TensorFlow / Keras
- NumPy

---

## â–¶ï¸ Run the Application
```cmd
python app.py  
```
Press **Q** to quit the application.

---

## ğŸ“Š Dataset

- ASL Alphabet Dataset  
- ~87,000 images  
- 29 classes  
- Used data augmentation and normalization  
- Trained on Kaggle with GPU support  

---

## ğŸ“ˆ Performance

- Mixed precision training  
- GPU-accelerated training (Tesla P100)  
- Real-time inference on CPU systems  

---

## ğŸ”® Future Enhancements

- Word and sentence-level ASL translation  
- NLP-based grammar correction  
- Text-to-speech support  
- Dynamic gesture recognition  
- Web or mobile deployment  

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## ğŸ‘¤ Author

**Yarramaddi Kishor Kumar Reddy**  
GitHub: https://github.com/kishor2004reddy  

---

## â­ Acknowledgements

- MediaPipe (Google)  
- TensorFlow & Keras  
- ASL Alphabet Dataset  
- Open-source ML community  

â­ If you like this project, give it a star on GitHub!

